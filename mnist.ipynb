{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ikyro/mnist/blob/main/mnist.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JBCWU50vr4yM"
      },
      "source": [
        "# Download `training data` and `test data`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 157,
      "metadata": {
        "id": "X5ZVIOAvdcQ7"
      },
      "outputs": [],
      "source": [
        "from torchvision import datasets\n",
        "from torchvision.transforms import ToTensor\n",
        "\n",
        "training_data = datasets.MNIST(\n",
        "  root='data',\n",
        "  train=True,\n",
        "  download=True,\n",
        "  transform=ToTensor()\n",
        ")\n",
        "\n",
        "test_data = datasets.MNIST(\n",
        "  root='data',\n",
        "  train=False,\n",
        "  download=True,\n",
        "  transform=ToTensor()\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 158,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 628
        },
        "id": "BIGKzIXum5N0",
        "outputId": "1c68a315-411a-4912-8df1-084899724e4f"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 600x600 with 9 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import torch\n",
        "\n",
        "figure = plt.figure(figsize=(6, 6), layout='constrained')\n",
        "cols = 3\n",
        "rows = 3\n",
        "\n",
        "for i in range(cols * rows):\n",
        "  rand_index = torch.randint(len(training_data), size=(1,)).item()\n",
        "  img, label = training_data[rand_index] # type: ignore\n",
        "  figure.add_subplot(rows, cols, i + 1)\n",
        "  plt.title(label)\n",
        "  plt.axis('off')\n",
        "  plt.imshow(img.squeeze(), cmap='gray')\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 159,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "htu9MaHOM52S",
        "outputId": "11bea652-f321-4e32-f6f8-01f322d4dff9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "training data size: torch.Size([60000, 28, 28])\n",
            "test data size: torch.Size([10000, 28, 28])\n"
          ]
        }
      ],
      "source": [
        "print(\n",
        "  f'training data size: {training_data.data.size()}',\n",
        "  f'test data size: {test_data.data.size()}',\n",
        "  sep='\\n'\n",
        ")\n",
        "\n",
        "#print(training_data.data.size()[1:])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 160,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XdobnXfkqDUl",
        "outputId": "6f888265-0105-43c9-c731-2aee0683c656"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "using: cuda\n"
          ]
        }
      ],
      "source": [
        "from torch import cuda\n",
        "\n",
        "device = 'cuda' if cuda.is_available() else 'cpu'\n",
        "\n",
        "print(f'using: {device}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 161,
      "metadata": {
        "id": "_d86QlHTxBSn"
      },
      "outputs": [],
      "source": [
        "from torch import nn\n",
        "\n",
        "class NeuralNetwork(nn.Module):\n",
        "  def __init__(self):\n",
        "    super().__init__()\n",
        "\n",
        "    self.flatten = nn.Flatten()\n",
        "    self.linear_relu_stack = nn.Sequential(\n",
        "      nn.Linear(in_features=28*28, out_features=512),\n",
        "      nn.ReLU(),\n",
        "      nn.Linear(in_features=512, out_features=512),\n",
        "      nn.ReLU(),\n",
        "      nn.Linear(in_features=512, out_features=10)\n",
        "    )\n",
        "\n",
        "  def forward(self, x):\n",
        "    x = self.flatten(x)\n",
        "    logits = self.linear_relu_stack(x)\n",
        "\n",
        "    return logits"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Data Loaders"
      ],
      "metadata": {
        "id": "Z2bPUdaVQ-Vi"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 162,
      "metadata": {
        "id": "sth14QNkudBJ"
      },
      "outputs": [],
      "source": [
        "from torch.utils.data import DataLoader\n",
        "\n",
        "training_loader = DataLoader(\n",
        "  training_data,\n",
        "  batch_size=100,\n",
        "  shuffle=True,\n",
        "  num_workers=2,\n",
        "  pin_memory=True,\n",
        ")\n",
        "\n",
        "test_loader = DataLoader(\n",
        "  test_data,\n",
        "  batch_size=100,\n",
        "  shuffle=True,\n",
        "  num_workers=2,\n",
        "  pin_memory=True,\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Model Instance"
      ],
      "metadata": {
        "id": "AnGanuvyszJx"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 163,
      "metadata": {
        "id": "p__TOMMsMpsL"
      },
      "outputs": [],
      "source": [
        "model = NeuralNetwork().to(device)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m0w369diFsOp"
      },
      "source": [
        "# Training Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 175,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4jKrh_hXbrfM",
        "outputId": "97fa504b-fac2-47a1-e5b4-f61c82efec33"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "training epoch: [1/5]\n",
            "loss: 0.0008 [1000/60000]\n",
            "loss: 0.0001 [2000/60000]\n",
            "loss: 0.0001 [3000/60000]\n",
            "loss: 0.0000 [4000/60000]\n",
            "loss: 0.0005 [5000/60000]\n",
            "loss: 0.0103 [6000/60000]\n",
            "loss: 0.0002 [7000/60000]\n",
            "loss: 0.0000 [8000/60000]\n",
            "loss: 0.0000 [9000/60000]\n",
            "loss: 0.0001 [10000/60000]\n",
            "loss: 0.0003 [11000/60000]\n",
            "loss: 0.0002 [12000/60000]\n",
            "loss: 0.0048 [13000/60000]\n",
            "loss: 0.0002 [14000/60000]\n",
            "loss: 0.0005 [15000/60000]\n",
            "loss: 0.0054 [16000/60000]\n",
            "loss: 0.0000 [17000/60000]\n",
            "loss: 0.0076 [18000/60000]\n",
            "loss: 0.0000 [19000/60000]\n",
            "loss: 0.0157 [20000/60000]\n",
            "loss: 0.0026 [21000/60000]\n",
            "loss: 0.0000 [22000/60000]\n",
            "loss: 0.0002 [23000/60000]\n",
            "loss: 0.0000 [24000/60000]\n",
            "loss: 0.0054 [25000/60000]\n",
            "loss: 0.0001 [26000/60000]\n",
            "loss: 0.0171 [27000/60000]\n",
            "loss: 0.0001 [28000/60000]\n",
            "loss: 0.0014 [29000/60000]\n",
            "loss: 0.0011 [30000/60000]\n",
            "loss: 0.0005 [31000/60000]\n",
            "loss: 0.0001 [32000/60000]\n",
            "loss: 0.0011 [33000/60000]\n",
            "loss: 0.0000 [34000/60000]\n",
            "loss: 0.0162 [35000/60000]\n",
            "loss: 0.0023 [36000/60000]\n",
            "loss: 0.0049 [37000/60000]\n",
            "loss: 0.0687 [38000/60000]\n",
            "loss: 0.0090 [39000/60000]\n",
            "loss: 0.0370 [40000/60000]\n",
            "loss: 0.0002 [41000/60000]\n",
            "loss: 0.0023 [42000/60000]\n",
            "loss: 0.0002 [43000/60000]\n",
            "loss: 0.0013 [44000/60000]\n",
            "loss: 0.0158 [45000/60000]\n",
            "loss: 0.0007 [46000/60000]\n",
            "loss: 0.0060 [47000/60000]\n",
            "loss: 0.0088 [48000/60000]\n",
            "loss: 0.0014 [49000/60000]\n",
            "loss: 0.0141 [50000/60000]\n",
            "loss: 0.0000 [51000/60000]\n",
            "loss: 0.0001 [52000/60000]\n",
            "loss: 0.0000 [53000/60000]\n",
            "loss: 0.0000 [54000/60000]\n",
            "loss: 0.0008 [55000/60000]\n",
            "loss: 0.0481 [56000/60000]\n",
            "loss: 0.0040 [57000/60000]\n",
            "loss: 0.0001 [58000/60000]\n",
            "loss: 0.0027 [59000/60000]\n",
            "loss: 0.0203 [60000/60000]\n",
            "training epoch: [2/5]\n",
            "loss: 0.0014 [1000/60000]\n",
            "loss: 0.0000 [2000/60000]\n",
            "loss: 0.0009 [3000/60000]\n",
            "loss: 0.0012 [4000/60000]\n",
            "loss: 0.0030 [5000/60000]\n",
            "loss: 0.0000 [6000/60000]\n",
            "loss: 0.0085 [7000/60000]\n",
            "loss: 0.0000 [8000/60000]\n",
            "loss: 0.0004 [9000/60000]\n",
            "loss: 0.0094 [10000/60000]\n",
            "loss: 0.0001 [11000/60000]\n",
            "loss: 0.0000 [12000/60000]\n",
            "loss: 0.0069 [13000/60000]\n",
            "loss: 0.0015 [14000/60000]\n",
            "loss: 0.0017 [15000/60000]\n",
            "loss: 0.0002 [16000/60000]\n",
            "loss: 0.0081 [17000/60000]\n",
            "loss: 0.0002 [18000/60000]\n",
            "loss: 0.0042 [19000/60000]\n",
            "loss: 0.0002 [20000/60000]\n",
            "loss: 0.0279 [21000/60000]\n",
            "loss: 0.0064 [22000/60000]\n",
            "loss: 0.0076 [23000/60000]\n",
            "loss: 0.0011 [24000/60000]\n",
            "loss: 0.0001 [25000/60000]\n",
            "loss: 0.0001 [26000/60000]\n",
            "loss: 0.0101 [27000/60000]\n",
            "loss: 0.0000 [28000/60000]\n",
            "loss: 0.0001 [29000/60000]\n",
            "loss: 0.0000 [30000/60000]\n",
            "loss: 0.0048 [31000/60000]\n",
            "loss: 0.0000 [32000/60000]\n",
            "loss: 0.0134 [33000/60000]\n",
            "loss: 0.0000 [34000/60000]\n",
            "loss: 0.0059 [35000/60000]\n",
            "loss: 0.0001 [36000/60000]\n",
            "loss: 0.0111 [37000/60000]\n",
            "loss: 0.0001 [38000/60000]\n",
            "loss: 0.0023 [39000/60000]\n",
            "loss: 0.0001 [40000/60000]\n",
            "loss: 0.0000 [41000/60000]\n",
            "loss: 0.0001 [42000/60000]\n",
            "loss: 0.0074 [43000/60000]\n",
            "loss: 0.0063 [44000/60000]\n",
            "loss: 0.0535 [45000/60000]\n",
            "loss: 0.0017 [46000/60000]\n",
            "loss: 0.0004 [47000/60000]\n",
            "loss: 0.0031 [48000/60000]\n",
            "loss: 0.0005 [49000/60000]\n",
            "loss: 0.0008 [50000/60000]\n",
            "loss: 0.0257 [51000/60000]\n",
            "loss: 0.0001 [52000/60000]\n",
            "loss: 0.0001 [53000/60000]\n",
            "loss: 0.0036 [54000/60000]\n",
            "loss: 0.0019 [55000/60000]\n",
            "loss: 0.0005 [56000/60000]\n",
            "loss: 0.0006 [57000/60000]\n",
            "loss: 0.0001 [58000/60000]\n",
            "loss: 0.0412 [59000/60000]\n",
            "loss: 0.0005 [60000/60000]\n",
            "training epoch: [3/5]\n",
            "loss: 0.0002 [1000/60000]\n",
            "loss: 0.0002 [2000/60000]\n",
            "loss: 0.0087 [3000/60000]\n",
            "loss: 0.0000 [4000/60000]\n",
            "loss: 0.0000 [5000/60000]\n",
            "loss: 0.0003 [6000/60000]\n",
            "loss: 0.0000 [7000/60000]\n",
            "loss: 0.0004 [8000/60000]\n",
            "loss: 0.0002 [9000/60000]\n",
            "loss: 0.0000 [10000/60000]\n",
            "loss: 0.0003 [11000/60000]\n",
            "loss: 0.0051 [12000/60000]\n",
            "loss: 0.0000 [13000/60000]\n",
            "loss: 0.0001 [14000/60000]\n",
            "loss: 0.0001 [15000/60000]\n",
            "loss: 0.0005 [16000/60000]\n",
            "loss: 0.0001 [17000/60000]\n",
            "loss: 0.0001 [18000/60000]\n",
            "loss: 0.0015 [19000/60000]\n",
            "loss: 0.0019 [20000/60000]\n",
            "loss: 0.0009 [21000/60000]\n",
            "loss: 0.0002 [22000/60000]\n",
            "loss: 0.0181 [23000/60000]\n",
            "loss: 0.0026 [24000/60000]\n",
            "loss: 0.0039 [25000/60000]\n",
            "loss: 0.0061 [26000/60000]\n",
            "loss: 0.0086 [27000/60000]\n",
            "loss: 0.0000 [28000/60000]\n",
            "loss: 0.0189 [29000/60000]\n",
            "loss: 0.0000 [30000/60000]\n",
            "loss: 0.0017 [31000/60000]\n",
            "loss: 0.0001 [32000/60000]\n",
            "loss: 0.0002 [33000/60000]\n",
            "loss: 0.0000 [34000/60000]\n",
            "loss: 0.0045 [35000/60000]\n",
            "loss: 0.0003 [36000/60000]\n",
            "loss: 0.0002 [37000/60000]\n",
            "loss: 0.0000 [38000/60000]\n",
            "loss: 0.0028 [39000/60000]\n",
            "loss: 0.0122 [40000/60000]\n",
            "loss: 0.0012 [41000/60000]\n",
            "loss: 0.0000 [42000/60000]\n",
            "loss: 0.0001 [43000/60000]\n",
            "loss: 0.0084 [44000/60000]\n",
            "loss: 0.0000 [45000/60000]\n",
            "loss: 0.0029 [46000/60000]\n",
            "loss: 0.0119 [47000/60000]\n",
            "loss: 0.0016 [48000/60000]\n",
            "loss: 0.1092 [49000/60000]\n",
            "loss: 0.0000 [50000/60000]\n",
            "loss: 0.0015 [51000/60000]\n",
            "loss: 0.1104 [52000/60000]\n",
            "loss: 0.0081 [53000/60000]\n",
            "loss: 0.0003 [54000/60000]\n",
            "loss: 0.0019 [55000/60000]\n",
            "loss: 0.0030 [56000/60000]\n",
            "loss: 0.0000 [57000/60000]\n",
            "loss: 0.0050 [58000/60000]\n",
            "loss: 0.0023 [59000/60000]\n",
            "loss: 0.0044 [60000/60000]\n",
            "training epoch: [4/5]\n",
            "loss: 0.0001 [1000/60000]\n",
            "loss: 0.0011 [2000/60000]\n",
            "loss: 0.0001 [3000/60000]\n",
            "loss: 0.0001 [4000/60000]\n",
            "loss: 0.0006 [5000/60000]\n",
            "loss: 0.0024 [6000/60000]\n",
            "loss: 0.0000 [7000/60000]\n",
            "loss: 0.0011 [8000/60000]\n",
            "loss: 0.0002 [9000/60000]\n",
            "loss: 0.0001 [10000/60000]\n",
            "loss: 0.0479 [11000/60000]\n",
            "loss: 0.0004 [12000/60000]\n",
            "loss: 0.0005 [13000/60000]\n",
            "loss: 0.0001 [14000/60000]\n",
            "loss: 0.0002 [15000/60000]\n",
            "loss: 0.0044 [16000/60000]\n",
            "loss: 0.0151 [17000/60000]\n",
            "loss: 0.0002 [18000/60000]\n",
            "loss: 0.0000 [19000/60000]\n",
            "loss: 0.0008 [20000/60000]\n",
            "loss: 0.0003 [21000/60000]\n",
            "loss: 0.0000 [22000/60000]\n",
            "loss: 0.0001 [23000/60000]\n",
            "loss: 0.0000 [24000/60000]\n",
            "loss: 0.0000 [25000/60000]\n",
            "loss: 0.0814 [26000/60000]\n",
            "loss: 0.0019 [27000/60000]\n",
            "loss: 0.0005 [28000/60000]\n",
            "loss: 0.0001 [29000/60000]\n",
            "loss: 0.0003 [30000/60000]\n",
            "loss: 0.0000 [31000/60000]\n",
            "loss: 0.0000 [32000/60000]\n",
            "loss: 0.0004 [33000/60000]\n",
            "loss: 0.0000 [34000/60000]\n",
            "loss: 0.0025 [35000/60000]\n",
            "loss: 0.0370 [36000/60000]\n",
            "loss: 0.0021 [37000/60000]\n",
            "loss: 0.0000 [38000/60000]\n",
            "loss: 0.0463 [39000/60000]\n",
            "loss: 0.0004 [40000/60000]\n",
            "loss: 0.0209 [41000/60000]\n",
            "loss: 0.0001 [42000/60000]\n",
            "loss: 0.0063 [43000/60000]\n",
            "loss: 0.0012 [44000/60000]\n",
            "loss: 0.0000 [45000/60000]\n",
            "loss: 0.0008 [46000/60000]\n",
            "loss: 0.0011 [47000/60000]\n",
            "loss: 0.0005 [48000/60000]\n",
            "loss: 0.0000 [49000/60000]\n",
            "loss: 0.0024 [50000/60000]\n",
            "loss: 0.0004 [51000/60000]\n",
            "loss: 0.0506 [52000/60000]\n",
            "loss: 0.0007 [53000/60000]\n",
            "loss: 0.0058 [54000/60000]\n",
            "loss: 0.0022 [55000/60000]\n",
            "loss: 0.0001 [56000/60000]\n",
            "loss: 0.0029 [57000/60000]\n",
            "loss: 0.0060 [58000/60000]\n",
            "loss: 0.0037 [59000/60000]\n",
            "loss: 0.0002 [60000/60000]\n",
            "training epoch: [5/5]\n",
            "loss: 0.0807 [1000/60000]\n",
            "loss: 0.0033 [2000/60000]\n",
            "loss: 0.0000 [3000/60000]\n",
            "loss: 0.0132 [4000/60000]\n",
            "loss: 0.0000 [5000/60000]\n",
            "loss: 0.0001 [6000/60000]\n",
            "loss: 0.0000 [7000/60000]\n",
            "loss: 0.0004 [8000/60000]\n",
            "loss: 0.0613 [9000/60000]\n",
            "loss: 0.1038 [10000/60000]\n",
            "loss: 0.0046 [11000/60000]\n",
            "loss: 0.0023 [12000/60000]\n",
            "loss: 0.0000 [13000/60000]\n",
            "loss: 0.0002 [14000/60000]\n",
            "loss: 0.0303 [15000/60000]\n",
            "loss: 0.0000 [16000/60000]\n",
            "loss: 0.0000 [17000/60000]\n",
            "loss: 0.0006 [18000/60000]\n",
            "loss: 0.0006 [19000/60000]\n",
            "loss: 0.0008 [20000/60000]\n",
            "loss: 0.0007 [21000/60000]\n",
            "loss: 0.0002 [22000/60000]\n",
            "loss: 0.0010 [23000/60000]\n",
            "loss: 0.0325 [24000/60000]\n",
            "loss: 0.0058 [25000/60000]\n",
            "loss: 0.0116 [26000/60000]\n",
            "loss: 0.0632 [27000/60000]\n",
            "loss: 0.0006 [28000/60000]\n",
            "loss: 0.0058 [29000/60000]\n",
            "loss: 0.0275 [30000/60000]\n",
            "loss: 0.0000 [31000/60000]\n",
            "loss: 0.0090 [32000/60000]\n",
            "loss: 0.0144 [33000/60000]\n",
            "loss: 0.0846 [34000/60000]\n",
            "loss: 0.0028 [35000/60000]\n",
            "loss: 0.0002 [36000/60000]\n",
            "loss: 0.0001 [37000/60000]\n",
            "loss: 0.0008 [38000/60000]\n",
            "loss: 0.0021 [39000/60000]\n",
            "loss: 0.0014 [40000/60000]\n",
            "loss: 0.0000 [41000/60000]\n",
            "loss: 0.0707 [42000/60000]\n",
            "loss: 0.0001 [43000/60000]\n",
            "loss: 0.0026 [44000/60000]\n",
            "loss: 0.0002 [45000/60000]\n",
            "loss: 0.0000 [46000/60000]\n",
            "loss: 0.0010 [47000/60000]\n",
            "loss: 0.0001 [48000/60000]\n",
            "loss: 0.0002 [49000/60000]\n",
            "loss: 0.0012 [50000/60000]\n",
            "loss: 0.0004 [51000/60000]\n",
            "loss: 0.0003 [52000/60000]\n",
            "loss: 0.0151 [53000/60000]\n",
            "loss: 0.0003 [54000/60000]\n",
            "loss: 0.0000 [55000/60000]\n",
            "loss: 0.0004 [56000/60000]\n",
            "loss: 0.0276 [57000/60000]\n",
            "loss: 0.0000 [58000/60000]\n",
            "loss: 0.0000 [59000/60000]\n",
            "loss: 0.0023 [60000/60000]\n"
          ]
        }
      ],
      "source": [
        "from torch import nn, optim\n",
        "import numpy as np\n",
        "\n",
        "loss_fn = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters())\n",
        "epochs = 5\n",
        "\n",
        "def train_model():\n",
        "  for i, (inputs, labels) in enumerate(training_loader, start=1):\n",
        "    inputs = inputs.to(device)\n",
        "    labels = labels.clone().detach().to(device)\n",
        "\n",
        "    optimizer.zero_grad()\n",
        "    outputs = model(inputs)\n",
        "    loss = loss_fn(outputs, labels)\n",
        "\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    if i % 10 == 0:\n",
        "      current = i * len(inputs)\n",
        "\n",
        "      print(\n",
        "        f'loss: {loss.item():.4f}',\n",
        "        f'[{current}/{len(training_data)}]'\n",
        "      )\n",
        "\n",
        "for epoch in range(1, epochs + 1):\n",
        "  print(f'training epoch: [{epoch}/{epochs}]')\n",
        "\n",
        "  model.train()\n",
        "  train_model()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qjDsa2URF5Nl"
      },
      "source": [
        "# Evaluation Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 176,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Gdg8_bRUFcbs",
        "outputId": "0064ff79-7746-4cb5-f5d8-9003ec28ad84"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch: [1/5]\n",
            "loss: 0.0521 acc: 0.9800 [500/10000]\n",
            "loss: 0.0493 acc: 0.9900 [1000/10000]\n",
            "loss: 0.2351 acc: 0.9700 [1500/10000]\n",
            "loss: 0.0609 acc: 0.9800 [2000/10000]\n",
            "loss: 0.0002 acc: 1.0000 [2500/10000]\n",
            "loss: 0.0002 acc: 1.0000 [3000/10000]\n",
            "loss: 0.0001 acc: 1.0000 [3500/10000]\n",
            "loss: 0.1836 acc: 0.9800 [4000/10000]\n",
            "loss: 0.0216 acc: 0.9900 [4500/10000]\n",
            "loss: 0.2257 acc: 0.9700 [5000/10000]\n",
            "loss: 0.0072 acc: 1.0000 [5500/10000]\n",
            "loss: 0.3239 acc: 0.9800 [6000/10000]\n",
            "loss: 0.2553 acc: 0.9800 [6500/10000]\n",
            "loss: 0.4591 acc: 0.9700 [7000/10000]\n",
            "loss: 0.0855 acc: 0.9900 [7500/10000]\n",
            "loss: 0.0748 acc: 0.9900 [8000/10000]\n",
            "loss: 0.0541 acc: 0.9900 [8500/10000]\n",
            "loss: 0.0166 acc: 0.9900 [9000/10000]\n",
            "loss: 0.0605 acc: 0.9800 [9500/10000]\n",
            "loss: 0.2136 acc: 0.9800 [10000/10000]\n",
            "epoch: [2/5]\n",
            "loss: 0.2723 acc: 0.9700 [500/10000]\n",
            "loss: 0.0849 acc: 0.9900 [1000/10000]\n",
            "loss: 0.0471 acc: 0.9900 [1500/10000]\n",
            "loss: 0.3087 acc: 0.9400 [2000/10000]\n",
            "loss: 0.0082 acc: 1.0000 [2500/10000]\n",
            "loss: 0.0001 acc: 1.0000 [3000/10000]\n",
            "loss: 0.1836 acc: 0.9800 [3500/10000]\n",
            "loss: 0.0063 acc: 1.0000 [4000/10000]\n",
            "loss: 0.1078 acc: 0.9800 [4500/10000]\n",
            "loss: 0.1059 acc: 0.9700 [5000/10000]\n",
            "loss: 0.0508 acc: 0.9700 [5500/10000]\n",
            "loss: 0.0010 acc: 1.0000 [6000/10000]\n",
            "loss: 0.0808 acc: 0.9900 [6500/10000]\n",
            "loss: 0.0188 acc: 0.9900 [7000/10000]\n",
            "loss: 0.0504 acc: 0.9900 [7500/10000]\n",
            "loss: 0.0106 acc: 1.0000 [8000/10000]\n",
            "loss: 0.0045 acc: 1.0000 [8500/10000]\n",
            "loss: 0.0999 acc: 0.9900 [9000/10000]\n",
            "loss: 0.1354 acc: 0.9700 [9500/10000]\n",
            "loss: 0.1271 acc: 0.9900 [10000/10000]\n",
            "epoch: [3/5]\n",
            "loss: 0.0768 acc: 0.9900 [500/10000]\n",
            "loss: 0.0162 acc: 0.9900 [1000/10000]\n",
            "loss: 0.0099 acc: 1.0000 [1500/10000]\n",
            "loss: 0.0719 acc: 0.9800 [2000/10000]\n",
            "loss: 0.0178 acc: 0.9900 [2500/10000]\n",
            "loss: 0.0303 acc: 0.9800 [3000/10000]\n",
            "loss: 0.0959 acc: 0.9700 [3500/10000]\n",
            "loss: 0.1322 acc: 0.9800 [4000/10000]\n",
            "loss: 0.0868 acc: 0.9900 [4500/10000]\n",
            "loss: 0.0004 acc: 1.0000 [5000/10000]\n",
            "loss: 0.3991 acc: 0.9500 [5500/10000]\n",
            "loss: 0.1649 acc: 0.9900 [6000/10000]\n",
            "loss: 0.0270 acc: 0.9900 [6500/10000]\n",
            "loss: 0.0900 acc: 0.9800 [7000/10000]\n",
            "loss: 0.0615 acc: 0.9900 [7500/10000]\n",
            "loss: 0.0000 acc: 1.0000 [8000/10000]\n",
            "loss: 0.3434 acc: 0.9700 [8500/10000]\n",
            "loss: 0.2436 acc: 0.9800 [9000/10000]\n",
            "loss: 0.0554 acc: 0.9900 [9500/10000]\n",
            "loss: 0.0050 acc: 1.0000 [10000/10000]\n",
            "epoch: [4/5]\n",
            "loss: 0.0753 acc: 0.9800 [500/10000]\n",
            "loss: 0.1429 acc: 0.9800 [1000/10000]\n",
            "loss: 0.2831 acc: 0.9500 [1500/10000]\n",
            "loss: 0.1575 acc: 0.9900 [2000/10000]\n",
            "loss: 0.0331 acc: 0.9900 [2500/10000]\n",
            "loss: 0.0787 acc: 0.9800 [3000/10000]\n",
            "loss: 0.0547 acc: 0.9900 [3500/10000]\n",
            "loss: 0.0359 acc: 0.9800 [4000/10000]\n",
            "loss: 0.0052 acc: 1.0000 [4500/10000]\n",
            "loss: 0.0838 acc: 0.9900 [5000/10000]\n",
            "loss: 0.0336 acc: 0.9800 [5500/10000]\n",
            "loss: 0.0067 acc: 1.0000 [6000/10000]\n",
            "loss: 0.0636 acc: 0.9800 [6500/10000]\n",
            "loss: 0.0001 acc: 1.0000 [7000/10000]\n",
            "loss: 0.0859 acc: 0.9800 [7500/10000]\n",
            "loss: 0.1026 acc: 0.9900 [8000/10000]\n",
            "loss: 0.0014 acc: 1.0000 [8500/10000]\n",
            "loss: 0.0000 acc: 1.0000 [9000/10000]\n",
            "loss: 0.1062 acc: 0.9900 [9500/10000]\n",
            "loss: 0.2418 acc: 0.9600 [10000/10000]\n",
            "epoch: [5/5]\n",
            "loss: 0.0139 acc: 0.9900 [500/10000]\n",
            "loss: 0.0425 acc: 0.9700 [1000/10000]\n",
            "loss: 0.0755 acc: 0.9800 [1500/10000]\n",
            "loss: 0.0049 acc: 1.0000 [2000/10000]\n",
            "loss: 0.0259 acc: 0.9900 [2500/10000]\n",
            "loss: 0.3039 acc: 0.9700 [3000/10000]\n",
            "loss: 0.0025 acc: 1.0000 [3500/10000]\n",
            "loss: 0.0383 acc: 0.9800 [4000/10000]\n",
            "loss: 0.0306 acc: 0.9900 [4500/10000]\n",
            "loss: 0.0512 acc: 0.9900 [5000/10000]\n",
            "loss: 0.1030 acc: 0.9800 [5500/10000]\n",
            "loss: 0.0022 acc: 1.0000 [6000/10000]\n",
            "loss: 0.0006 acc: 1.0000 [6500/10000]\n",
            "loss: 0.0011 acc: 1.0000 [7000/10000]\n",
            "loss: 0.0727 acc: 0.9800 [7500/10000]\n",
            "loss: 0.0353 acc: 0.9800 [8000/10000]\n",
            "loss: 0.0479 acc: 0.9800 [8500/10000]\n",
            "loss: 0.0811 acc: 0.9900 [9000/10000]\n",
            "loss: 0.0001 acc: 1.0000 [9500/10000]\n",
            "loss: 0.2375 acc: 0.9700 [10000/10000]\n"
          ]
        }
      ],
      "source": [
        "def eval_model():\n",
        "  with torch.no_grad():\n",
        "    for i, (inputs, labels) in enumerate(test_loader, start=1):\n",
        "      inputs = inputs.to(device)\n",
        "      labels = labels.clone().detach().to(device)\n",
        "\n",
        "      outputs = model(inputs)\n",
        "      loss = loss_fn(outputs, labels)\n",
        "\n",
        "      if i % 5 == 0:\n",
        "        current = i * len(inputs)\n",
        "\n",
        "        print(f\"loss: {loss.item():.4f} acc: {(outputs.argmax(1) == labels).float().mean().item():.4f} [{current}/{len(test_data)}]\")\n",
        "\n",
        "for epoch in range(1, epochs + 1):\n",
        "  print(f'epoch: [{epoch}/{epochs}]')\n",
        "\n",
        "  model.eval()\n",
        "  eval_model()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Prediction Mode"
      ],
      "metadata": {
        "id": "UJKw_jmFQxRq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install Pillow"
      ],
      "metadata": {
        "id": "wKKsDiETMVJ8",
        "outputId": "3c01a207-75f4-4bab-d39d-9bcc637b3732",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 147,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.9/dist-packages (9.5.0)\n",
            "Requirement already satisfied: torchsummary in /usr/local/lib/python3.9/dist-packages (1.5.1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from PIL import Image\n",
        "import requests\n",
        "from io import BytesIO\n",
        "from torchvision import transforms\n",
        "\n",
        "transform = transforms.Compose([\n",
        "  transforms.Resize((28, 28)),\n",
        "  transforms.Grayscale(),\n",
        "  transforms.PILToTensor(),\n",
        "  transforms.ConvertImageDtype(torch.float32)\n",
        "])\n",
        "\n",
        "def show_image(url: str):\n",
        "  res = requests.get(url)\n",
        "  img = Image.open(BytesIO(res.content))\n",
        "\n",
        "  tensor = transform(img)\n",
        "\n",
        "  plt.axis('off')\n",
        "  plt.imshow(tensor.squeeze()) # type: ignore\n",
        "\n",
        "  return tensor\n",
        "\n",
        "img_tensor = show_image(input('url: '))\n",
        "print(img_tensor.shape) # type: ignore\n",
        "\n",
        "with torch.no_grad():\n",
        "  model.eval()\n",
        "  output = model(img_tensor.to(device)) # type: ignore\n",
        "  predicted = output.argmax().item()\n",
        "\n",
        "  print(output[0])\n",
        "  print(f'model preddiction: {predicted}')"
      ],
      "metadata": {
        "id": "3lguJRQBkIRR",
        "outputId": "66b4272f-4afb-453a-8f93-0dd34274ba15",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 498
        }
      },
      "execution_count": 180,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "url: https://p.kindpng.com/picc/s/770-7707591_silhouette-neck-hand-hand-written-number-9-hd.png\n",
            "torch.Size([1, 28, 28])\n",
            "tensor([ -9.0684, -16.7683, -20.3056,  -9.8334, -33.2004,   9.8081, -13.6425,\n",
            "         -0.5963, -31.2247, -16.1627], device='cuda:0')\n",
            "model preddiction: 5\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "nM7QRnL-uCqc"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.11"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}